{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2d79ad-2337-4851-86f0-d5b9cb91ee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义下载相关函数\n",
    "import os\n",
    "\n",
    "def aria2(url, filename, d):\n",
    "    !aria2c --console-log-level=error -c -x 16 -s 16 {url} -o {filename} -d {d}\n",
    "\n",
    "def download_from_oss(url, filename, save_dir):\n",
    "    url_prefix = {\n",
    "        \"cn-shanghai\": \"http://pai-vision-data-sh.oss-cn-shanghai-internal.aliyuncs.com\",\n",
    "        \"cn-hangzhou\": \"http://pai-vision-data-hz2.oss-cn-hangzhou-internal.aliyuncs.com\",\n",
    "        \"cn-shenzhen\": \"http://pai-vision-data-sz.oss-cn-shenzhen-internal.aliyuncs.com\",\n",
    "        \"cn-beijing\": \"http://pai-vision-data-bj.oss-cn-beijing-internal.aliyuncs.com\",\n",
    "        \"cn-wulanchabu\": \"https://pai-vision-data-wlcb.oss-cn-wulanchabu-internal.aliyuncs.com\",\n",
    "        \"ap-southeast-1\": \"http://pai-vision-data-ap-southeast.oss-ap-southeast-1-internal.aliyuncs.com\" \n",
    "    }\n",
    "    dsw_region = os.environ.get(\"dsw_region\")\n",
    "\n",
    "    prefix = url_prefix[dsw_region] if dsw_region in url_prefix else \"http://pai-vision-data-sh.oss-cn-shanghai.aliyuncs.com\"\n",
    "    url = os.path.join(prefix,url,filename)\n",
    "    print(url)\n",
    "    print(dsw_region)\n",
    "\n",
    "\n",
    "    print(f'Download from {url}')\n",
    "    !aria2c --console-log-level=error -c -x 16 -s 16 {url} -o {filename} -d {save_dir}\n",
    "\n",
    "    if filename.endswith('.tar.gz') or filename.endswith('.tar'):\n",
    "        saved_filepath = os.path.join(save_dir, filename)\n",
    "        print('Start Unzipping...')\n",
    "        !tar -xf $saved_filepath -C $save_dir\n",
    "        print('Done')\n",
    "\n",
    "        try:\n",
    "            os.remove(saved_filepath)\n",
    "            print(f'Removed original file: {saved_filepath}')\n",
    "        except OSError as e:\n",
    "            print(f\"Error: {saved_filepath} : {e.strerror}\")\n",
    "\n",
    "\n",
    "def check_files_exists_and_download(data_path, download_filenames):    \n",
    "    filenames = [\n",
    "        os.path.join(data_path, f\"models/Diffusion_Transformer/{name}\") for name in download_filenames\n",
    "    ]\n",
    "\n",
    "    for download_filename, filename in zip(download_filenames, filenames): \n",
    "        if os.path.exists(filename) or os.path.exists(filename.replace('.tar','').replace('.gz','')):\n",
    "            print('Exists. ', filename)\n",
    "            continue\n",
    "        save_dir = os.path.dirname(filename)\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        print(f\"Start Downloading: {download_filename} to {save_dir}\")\n",
    "        download_from_oss('aigc-data/cogvideox_fun/models', download_filename, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82dba82b-9fb3-4498-a494-4d92caaf44ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'EasyAnimate'...\n",
      "remote: Enumerating objects: 1603, done.\u001b[K\n",
      "remote: Counting objects: 100% (660/660), done.\u001b[K\n",
      "remote: Compressing objects: 100% (283/283), done.\u001b[K\n",
      "remote: Total 1603 (delta 541), reused 377 (delta 377), pack-reused 943 (from 3)\u001b[K\n",
      "Receiving objects: 100% (1603/1603), 4.30 MiB | 12.09 MiB/s, done.\n",
      "Resolving deltas: 100% (1028/1028), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/aigc-apps/EasyAnimate.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cde9e2b1-307e-4e22-a82f-606a997b4076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/EasyAnimate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (10.4.0)\n",
      "Requirement already satisfied: einops in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.8.1)\n",
      "Requirement already satisfied: safetensors in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.5.3)\n",
      "Requirement already satisfied: timm in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.0.15)\n",
      "Requirement already satisfied: tomesd in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.1.3)\n",
      "Requirement already satisfied: torch>=2.1.2 in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (2.6.0)\n",
      "Requirement already satisfied: torchdiffeq in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.2.5)\n",
      "Requirement already satisfied: torchsde in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.2.6)\n",
      "Requirement already satisfied: decord in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.6.0)\n",
      "Requirement already satisfied: datasets in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (3.5.0)\n",
      "Requirement already satisfied: numpy in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (1.26.4)\n",
      "Requirement already satisfied: scikit-image in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (0.25.2)\n",
      "Requirement already satisfied: opencv-python in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (4.11.0.86)\n",
      "Requirement already satisfied: omegaconf in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (2.3.0)\n",
      "Requirement already satisfied: SentencePiece in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (0.2.0)\n",
      "Requirement already satisfied: albumentations in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (2.0.5)\n",
      "Requirement already satisfied: imageio[ffmpeg] in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (2.37.0)\n",
      "Requirement already satisfied: tensorboard in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 19)) (2.19.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 20)) (4.13.3)\n",
      "Requirement already satisfied: ftfy in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 21)) (6.3.1)\n",
      "Requirement already satisfied: func_timeout in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 22)) (4.3.5)\n",
      "Requirement already satisfied: accelerate>=0.25.0 in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 23)) (1.6.0)\n",
      "Requirement already satisfied: gradio<=3.48.0,>=3.41.2 in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 24)) (3.48.0)\n",
      "Requirement already satisfied: diffusers<=0.31.0,>=0.30.1 in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 25)) (0.31.0)\n",
      "Requirement already satisfied: transformers>=4.46.2 in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 26)) (4.51.3)\n",
      "Requirement already satisfied: pyyaml in /venv/main/lib/python3.10/site-packages (from timm->-r requirements.txt (line 4)) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in /venv/main/lib/python3.10/site-packages (from timm->-r requirements.txt (line 4)) (0.30.2)\n",
      "Requirement already satisfied: torchvision in /venv/main/lib/python3.10/site-packages (from timm->-r requirements.txt (line 4)) (0.21.0)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /venv/main/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 6)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 6)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 6)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 6)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /venv/main/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 6)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /venv/main/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 6)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /venv/main/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 6)) (11.6.1.9)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 6)) (3.17.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /venv/main/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 6)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 6)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /venv/main/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 6)) (3.2.0)\n",
      "Requirement already satisfied: jinja2 in /venv/main/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 6)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /venv/main/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 6)) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /venv/main/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 6)) (1.13.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /venv/main/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 6)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 6)) (12.4.127)\n",
      "Requirement already satisfied: networkx in /venv/main/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 6)) (3.4.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /venv/main/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 6)) (2.21.5)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /venv/main/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 6)) (4.12.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /venv/main/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 6)) (12.4.5.8)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/main/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.1.2->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.4.0 in /venv/main/lib/python3.10/site-packages (from torchdiffeq->-r requirements.txt (line 7)) (1.15.2)\n",
      "Requirement already satisfied: trampoline>=0.1.2 in /venv/main/lib/python3.10/site-packages (from torchsde->-r requirements.txt (line 8)) (0.1.2)\n",
      "Requirement already satisfied: packaging in /venv/main/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 10)) (24.2)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /venv/main/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 10)) (0.3.8)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /venv/main/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 10)) (0.70.16)\n",
      "Requirement already satisfied: xxhash in /venv/main/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 10)) (3.5.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /venv/main/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 10)) (2.32.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /venv/main/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 10)) (19.0.1)\n",
      "Requirement already satisfied: pandas in /venv/main/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 10)) (2.2.3)\n",
      "Requirement already satisfied: aiohttp in /venv/main/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 10)) (3.11.16)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /venv/main/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 10)) (4.67.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /venv/main/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 12)) (2025.3.30)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /venv/main/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 12)) (0.4)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /venv/main/lib/python3.10/site-packages (from omegaconf->-r requirements.txt (line 14)) (4.9.3)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /venv/main/lib/python3.10/site-packages (from albumentations->-r requirements.txt (line 16)) (4.11.0.86)\n",
      "Requirement already satisfied: albucore==0.0.23 in /venv/main/lib/python3.10/site-packages (from albumentations->-r requirements.txt (line 16)) (0.0.23)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /venv/main/lib/python3.10/site-packages (from albumentations->-r requirements.txt (line 16)) (2.11.3)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /venv/main/lib/python3.10/site-packages (from albucore==0.0.23->albumentations->-r requirements.txt (line 16)) (3.12.4)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /venv/main/lib/python3.10/site-packages (from albucore==0.0.23->albumentations->-r requirements.txt (line 16)) (6.2.1)\n",
      "Requirement already satisfied: psutil in /venv/main/lib/python3.10/site-packages (from imageio[ffmpeg]->-r requirements.txt (line 17)) (6.1.1)\n",
      "Requirement already satisfied: imageio-ffmpeg in /venv/main/lib/python3.10/site-packages (from imageio[ffmpeg]->-r requirements.txt (line 17)) (0.6.0)\n",
      "Requirement already satisfied: av in /venv/main/lib/python3.10/site-packages (from imageio[ffmpeg]->-r requirements.txt (line 17)) (14.3.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /venv/main/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 19)) (3.8)\n",
      "Requirement already satisfied: six>1.9 in /venv/main/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 19)) (1.17.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /venv/main/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 19)) (1.71.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /venv/main/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 19)) (3.1.3)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /venv/main/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 19)) (6.30.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /venv/main/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 19)) (59.6.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /venv/main/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 19)) (0.7.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /venv/main/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 19)) (2.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /venv/main/lib/python3.10/site-packages (from beautifulsoup4->-r requirements.txt (line 20)) (2.6)\n",
      "Requirement already satisfied: wcwidth in /venv/main/lib/python3.10/site-packages (from ftfy->-r requirements.txt (line 21)) (0.2.13)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /venv/main/lib/python3.10/site-packages (from gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (0.34.1)\n",
      "Requirement already satisfied: gradio-client==0.6.1 in /venv/main/lib/python3.10/site-packages (from gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (0.6.1)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /venv/main/lib/python3.10/site-packages (from gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (23.2.1)\n",
      "Requirement already satisfied: orjson~=3.0 in /venv/main/lib/python3.10/site-packages (from gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (3.10.16)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /venv/main/lib/python3.10/site-packages (from gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (6.5.2)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /venv/main/lib/python3.10/site-packages (from gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (11.0.3)\n",
      "Requirement already satisfied: python-multipart in /venv/main/lib/python3.10/site-packages (from gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (0.0.20)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /venv/main/lib/python3.10/site-packages (from gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (2.1.5)\n",
      "Requirement already satisfied: pydub in /venv/main/lib/python3.10/site-packages (from gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (0.25.1)\n",
      "Requirement already satisfied: fastapi in /venv/main/lib/python3.10/site-packages (from gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (0.115.12)\n",
      "Requirement already satisfied: httpx in /venv/main/lib/python3.10/site-packages (from gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (0.28.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /venv/main/lib/python3.10/site-packages (from gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (5.5.0)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /venv/main/lib/python3.10/site-packages (from gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (3.10.1)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /venv/main/lib/python3.10/site-packages (from gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (2.10.0)\n",
      "Requirement already satisfied: ffmpy in /venv/main/lib/python3.10/site-packages (from gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (0.5.0)\n",
      "Requirement already satisfied: importlib-metadata in /venv/main/lib/python3.10/site-packages (from diffusers<=0.31.0,>=0.30.1->-r requirements.txt (line 25)) (8.6.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /venv/main/lib/python3.10/site-packages (from diffusers<=0.31.0,>=0.30.1->-r requirements.txt (line 25)) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /venv/main/lib/python3.10/site-packages (from transformers>=4.46.2->-r requirements.txt (line 26)) (0.21.1)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /venv/main/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /venv/main/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (1.35.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 10)) (25.3.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 10)) (5.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 10)) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 10)) (0.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 10)) (1.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 10)) (2.6.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 10)) (1.19.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 10)) (1.5.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /venv/main/lib/python3.10/site-packages (from matplotlib~=3.0->gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (4.57.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /venv/main/lib/python3.10/site-packages (from matplotlib~=3.0->gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (2.9.0.post0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /venv/main/lib/python3.10/site-packages (from matplotlib~=3.0->gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (3.2.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /venv/main/lib/python3.10/site-packages (from matplotlib~=3.0->gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (1.3.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /venv/main/lib/python3.10/site-packages (from matplotlib~=3.0->gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (1.4.8)\n",
      "Requirement already satisfied: cycler>=0.10 in /venv/main/lib/python3.10/site-packages (from matplotlib~=3.0->gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (0.12.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /venv/main/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 10)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /venv/main/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 10)) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /venv/main/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations->-r requirements.txt (line 16)) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /venv/main/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations->-r requirements.txt (line 16)) (0.4.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /venv/main/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations->-r requirements.txt (line 16)) (2.33.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /venv/main/lib/python3.10/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 10)) (2025.1.31)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.10/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 10)) (2.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /venv/main/lib/python3.10/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 10)) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /venv/main/lib/python3.10/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 10)) (3.4.1)\n",
      "Requirement already satisfied: h11>=0.8 in /venv/main/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (0.14.0)\n",
      "Requirement already satisfied: click>=7.0 in /venv/main/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (8.1.8)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /venv/main/lib/python3.10/site-packages (from fastapi->gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (0.46.2)\n",
      "Requirement already satisfied: httpcore==1.* in /venv/main/lib/python3.10/site-packages (from httpx->gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (1.0.8)\n",
      "Requirement already satisfied: anyio in /venv/main/lib/python3.10/site-packages (from httpx->gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (4.9.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /venv/main/lib/python3.10/site-packages (from importlib-metadata->diffusers<=0.31.0,>=0.30.1->-r requirements.txt (line 25)) (3.21.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /venv/main/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /venv/main/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /venv/main/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (0.24.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /venv/main/lib/python3.10/site-packages (from anyio->httpx->gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /venv/main/lib/python3.10/site-packages (from anyio->httpx->gradio<=3.48.0,>=3.41.2->-r requirements.txt (line 24)) (1.2.2)\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/EasyAnimate\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7591e30b-1258-4bcc-989f-14e5d44f8672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/EasyAnimate\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/EasyAnimate\n",
    "!mkdir -p datasets/internal_datasets/train "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f571da-cdf6-4022-9aa0-053b19206265",
   "metadata": {},
   "source": [
    "import os\n",
    "data_path = os.getcwd()\n",
    "download_from_oss('aigc-data/cogvideox_fun/code', 'code.tar.gz', data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f50cb8-8aa9-4d3b-9fbe-28953087449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载模型到指定目录 约3min\n",
    "import os\n",
    "data_path = os.path.join(os.getcwd(),'CogVideoX-Fun')\n",
    "\n",
    "# 下载预训练的模型\n",
    "check_files_exists_and_download(data_path, ['CogVideoX-Fun-2b-InP.tar.gz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b778c9af-a317-4d47-a25c-da90ea2c8354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: huggingface_hub in /home/ubuntu/.local/lib/python3.10/site-packages (0.29.3)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from huggingface_hub) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/lib/python3/dist-packages (from huggingface_hub) (2024.3.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from huggingface_hub) (3.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/lib/python3/dist-packages (from huggingface_hub) (21.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface_hub) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface_hub) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface_hub) (3.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 30 files: 100%|██████████| 30/30 [07:45<00:00, 15.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已下载至： /home/ubuntu/EasyAnimate/models--alibaba-pai--EasyAnimateV5.1-12b-zh-InP/snapshots/c0787d7ac5d75565255072e5889362d9c0b05509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 安装 huggingface_hub 库\n",
    "!pip install huggingface_hub\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# 指定模型仓库的 repo_id\n",
    "repo_id = \"alibaba-pai/EasyAnimateV5.1-12b-zh-InP\"\n",
    "\n",
    "# 指定下载到的目标目录\n",
    "target_dir = \"/workspace/EasyAnimate\"\n",
    "\n",
    "# 下载整个模型仓库的快照，指定缓存目录\n",
    "model_dir = snapshot_download(repo_id=repo_id, cache_dir=target_dir)\n",
    "\n",
    "print(\"模型已下载至：\", model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693960e4-2dc1-48c2-946b-b586a0b5259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#记住，把下载好的文件夹models--alibaba-pai--CogVideoX-Fun-V1.1-5b-InP直接重命名为 /models/Diffusion_Transformer/CogVideoX-Fun-2b-InP，复制太慢了，要一小时。\n",
    "!cp -r /workspace/CogVideoX-Fun/models/models--alibaba-pai--CogVideoX-Fun-V1.1-5b-InP/snapshots/b3798d82878e57443314b29d73633a165dd4c008/ /workspace/CogVideoX-Fun/models/Diffusion_Transformer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57300e60-4278-4d08-88a5-ac2e23e079d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -R /workspace/CogVideoX-Fun/models/Diffusion_Transformer/CogVideoX-Fun-2b-InP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7212786-ec21-4515-8269-149e0aa035ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "/venv/main/lib/python3.10/site-packages/gradio/components/dropdown.py:231: UserWarning: The value passed into gr.Dropdown() is not in the list of choices. Please update the list of choices to include: none or set allow_custom_value=True.\n",
      "  warnings.warn(\n",
      "/workspace/EasyAnimate/easyanimate/ui/ui.py:837: GradioUnusedKwargWarning: You have unused kwarg parameters in Image, please remove them: {'sources': 'upload'}\n",
      "  start_image = gr.Image(\n",
      "/workspace/EasyAnimate/easyanimate/ui/ui.py:864: GradioUnusedKwargWarning: You have unused kwarg parameters in Image, please remove them: {'sources': 'upload'}\n",
      "  end_image   = gr.Image(label=\"The image at the ending of the video (图片到视频的结束图片[非必需, Optional])\", show_label=False, elem_id=\"i2v_end\", sources=\"upload\", type=\"filepath\")\n",
      "/workspace/EasyAnimate/easyanimate/ui/ui.py:868: GradioUnusedKwargWarning: You have unused kwarg parameters in Video, please remove them: {'sources': 'upload'}\n",
      "  validation_video = gr.Video(\n",
      "/workspace/EasyAnimate/easyanimate/ui/ui.py:879: GradioUnusedKwargWarning: You have unused kwarg parameters in Image, please remove them: {'sources': 'upload'}\n",
      "  validation_video_mask = gr.Image(\n",
      "/workspace/EasyAnimate/easyanimate/ui/ui.py:892: GradioUnusedKwargWarning: You have unused kwarg parameters in Video, please remove them: {'sources': 'upload'}\n",
      "  control_video = gr.Video(\n",
      "/venv/main/lib/python3.10/site-packages/gradio/utils.py:812: UserWarning: Expected 2 arguments for function <function ui.<locals>.upload_generation_method at 0x7b8c989cd090>, received 1.\n",
      "  warnings.warn(\n",
      "/venv/main/lib/python3.10/site-packages/gradio/utils.py:816: UserWarning: Expected at least 2 arguments for function <function ui.<locals>.upload_generation_method at 0x7b8c989cd090>, received 1.\n",
      "  warnings.warn(\n",
      "Running on local URL:  http://0.0.0.0:7860\n",
      "IMPORTANT: You are using gradio version 3.48.0, however version 4.44.1 is available, please upgrade.\n",
      "--------\n",
      "Running on public URL: https://42b64811d6eb2b970b.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
      "Update diffusion transformer\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "loaded 3D transformer's pretrained weights from /workspace/EasyAnimate/models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "Traceback (most recent call last):\n",
      "  File \"/venv/main/lib/python3.10/site-packages/gradio/queueing.py\", line 407, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/venv/main/lib/python3.10/site-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/venv/main/lib/python3.10/site-packages/gradio/blocks.py\", line 1550, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/venv/main/lib/python3.10/site-packages/gradio/blocks.py\", line 1185, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/venv/main/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/venv/main/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/venv/main/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/venv/main/lib/python3.10/site-packages/gradio/utils.py\", line 661, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/workspace/EasyAnimate/easyanimate/ui/ui.py\", line 183, in update_diffusion_transformer\n",
      "    self.transformer = Choosen_Transformer3DModel.from_pretrained_2d(\n",
      "  File \"/workspace/EasyAnimate/easyanimate/models/transformer3d.py\", line 1702, in from_pretrained_2d\n",
      "    raise RuntimeError(f\"{config_file} does not exist\")\n",
      "RuntimeError: /workspace/EasyAnimate/models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer/config.json does not exist\n",
      "Traceback (most recent call last):\n",
      "  File \"/venv/main/lib/python3.10/site-packages/gradio/queueing.py\", line 407, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/venv/main/lib/python3.10/site-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/venv/main/lib/python3.10/site-packages/gradio/blocks.py\", line 1550, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/venv/main/lib/python3.10/site-packages/gradio/blocks.py\", line 1185, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/venv/main/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/venv/main/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/venv/main/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/venv/main/lib/python3.10/site-packages/gradio/utils.py\", line 661, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/workspace/EasyAnimate/easyanimate/ui/ui.py\", line 402, in generate\n",
      "    raise gr.Error(f\"Please select a pretrained model path.\")\n",
      "gradio.exceptions.Error: 'Please select a pretrained model path.'\n",
      "Traceback (most recent call last):\n",
      "  File \"/venv/main/lib/python3.10/site-packages/gradio/queueing.py\", line 407, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/venv/main/lib/python3.10/site-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/venv/main/lib/python3.10/site-packages/gradio/blocks.py\", line 1550, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/venv/main/lib/python3.10/site-packages/gradio/blocks.py\", line 1185, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/venv/main/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/venv/main/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/venv/main/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/venv/main/lib/python3.10/site-packages/gradio/utils.py\", line 661, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/workspace/EasyAnimate/easyanimate/ui/ui.py\", line 402, in generate\n",
      "    raise gr.Error(f\"Please select a pretrained model path.\")\n",
      "gradio.exceptions.Error: 'Please select a pretrained model path.'\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/EasyAnimate/app.py\", line 72, in <module>\n",
      "    time.sleep(5)\n",
      "KeyboardInterrupt\n",
      "Killing tunnel 0.0.0.0:7860 <> https://42b64811d6eb2b970b.gradio.live\n"
     ]
    }
   ],
   "source": [
    "!cd /workspace/EasyAnimate && python app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37a2c2f5-b796-4b8a-b893-3e40269eb916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件夹 '/home/ubuntu/EasyAnimate/models' 及其内容已成功删除。\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/workspace/EasyAnimate/models'  # 替换为你要删除的文件夹路径\n",
    "!rm -r \"$folder_path\"\n",
    "print(f\"文件夹 '{folder_path}' 及其内容已成功删除。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f0fc0a5-b7ac-407a-9de3-53e8b3eefcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat 'snapshots': No such file or directory\n",
      "/bin/bash: line 1: cd: /home/ubuntu/EasyAnimate/models/Diffusion_Transformer: No such file or directory\n",
      "mv: cannot stat 'snapshots': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!cd /workspace/EasyAnimate\n",
    "#第一步根据下载模型的不同，需要自己重命名\n",
    "!mv models--alibaba-pai--EasyAnimateV5.1-12b-zh-InP models \n",
    "!cd /workspace/EasyAnimate/models\n",
    "!mv snapshots Diffusion_Transformer\n",
    "!cd /workspace/EasyAnimate/models/Diffusion_Transformer\n",
    "!mv snapshots EasyAnimateV5.1-12b-zh-InP\n",
    "#最后一步根据下载模型的不同，需要自己重命名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78de956a-7463-4a7c-82ed-e7f61f346ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/workspace/EasyAnimate/models/'  # 替换为你要删除的文件夹路径\n",
    "!rm -r \"$folder_path\"\n",
    "print(f\"文件夹 '{folder_path}' 及其内容已成功删除。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc2b905-aaf3-4e4f-8fcd-36599eab78d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r /root/.cache/huggingface/hub/models--alibaba-pai--CogVideoX-Fun-V1.5-5b-InP /workspace/EasyAnimate/models/Diffusion_Transformer/CogVideoX-Fun-V1.1-2b-InP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35f1f281-64b1-4409-a513-81e3e793d8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.41it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1273: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  if clip_image is not None and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:40<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/EasyAnimate && python /workspace/EasyAnimate/predict_t2v.py --prompt \"一只可爱的猫咪在窗边晒太阳\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27120055-2514-409e-9c82-fc3d06fe53dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/EasyAnimate\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.63it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.20it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.47it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.47it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.61it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.20it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.41it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.64it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.78it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.57it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.43it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.37it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.63it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.67it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.20it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.78it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.72it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.20it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 28.12it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 28.08it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.20it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.49it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.46it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.32it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.36it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.22it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.78it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.77it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.85it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.27it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.27it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.20it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.93it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:43<00:00,  1.16it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.13it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.04it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.95it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.77it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.96it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.34it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.51it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.96it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.12it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.69it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.66it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.81it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.58it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.91it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.02it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.48it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.87it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.00it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.20it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.55it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:40<00:00,  1.23it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.34it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:40<00:00,  1.23it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.40it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.56it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.34it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.20it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.41it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "#50条没有previousscene next的, 0-50或者49\n",
    "%cd /workspace/EasyAnimate\n",
    "!sh generate_videos_from_captions.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d16c306c-0fba-40f5-86f1-1a6c37ab645a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/EasyAnimate\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.67it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:43<00:00,  1.16it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.65it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.30it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.20it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.27it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.21it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.41it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.18it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.85it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.20it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.66it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.20it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.66it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.68it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.78it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.65it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.25it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.16it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.16it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.44it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.30it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.52it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.90it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.93it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 25.84it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.64it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.20it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.54it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.84it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.49it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.02it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.31it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.20it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.40it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.98it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.20it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.64it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.87it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.76it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.17it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.12it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.20it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 28.38it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.59it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.62it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.20it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.97it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.63it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.20it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.16it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.20it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.47it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.21it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.98it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.76it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.63it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.89it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.72it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.12it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.62it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.20it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.88it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.39it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.72it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "#50条有previousscene next的，50到99或者100\n",
    "%cd /workspace/EasyAnimate\n",
    "!sh generate_videos_with_scenes_group_B.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a400804d-07c2-4a59-b0b1-280e9ac16175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/EasyAnimate\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.58it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.32it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.21it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.61it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 28.37it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:40<00:00,  1.22it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.68it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 28.11it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.59it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.70it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.29it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.20it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.86it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.87it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.65it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.58it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.71it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.64it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.24it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.20it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.45it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.94it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.87it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.80it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.19it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.47it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.00it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.20it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.82it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 28.28it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:43<00:00,  1.16it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.13it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.15it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.25it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.89it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.81it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 25.86it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.40it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.94it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.98it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.21it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.94it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.72it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.86it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.21it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.42it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.17it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:41<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.51it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.57it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.53it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.98it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.39it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.83it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 27.40it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.98it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.29it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.19it/s]\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/tokenizer\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:00<00:00, 26.44it/s]\n",
      "Enable TeaCache with threshold: 0.08.\n",
      "/workspace/EasyAnimate/easyanimate/pipeline/pipeline_easyanimate_inpaint.py:1296: FutureWarning: Accessing config attribute `enable_clip_in_inpaint` directly via 'EasyAnimateTransformer3DModel' object attribute is deprecated. Please access 'enable_clip_in_inpaint' over 'EasyAnimateTransformer3DModel's config object instead, e.g. 'unet.config.enable_clip_in_inpaint'.\n",
      "  elif clip_image is None and num_channels_transformer != num_channels_latents and self.transformer.enable_clip_in_inpaint:\n",
      "100%|███████████████████████████████████████████| 50/50 [00:42<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "#groupc 100-150, just single scene, single sentence, single prompt\n",
    "%cd /workspace/EasyAnimate\n",
    "!sh generate_videos_from_group_c_single.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5101382a-ec74-48d2-b23c-f1e0af3c840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载示例数据\n",
    "data_path = os.path.join(os.getcwd(),'EasyAnimate/datasets')\n",
    "download_from_oss('aigc-data/easyanimate/data', 'data.tar.gz', data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e09ad71-ee30-4582-ba03-2d7adfa35710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808e9700-619b-49ad-b67b-77f4ade6c24d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train lora model\n",
    "# 您可修改 scripts/train_lora.sh 中的相关参数（如增大训练epoch数 num_train_epochs）来达到更好的性能。\n",
    "#注意metadata.json是image还是video\n",
    "!cd /workspace/EasyAnimate && sh scripts/train_lora.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afa905c-fe43-41de-9371-f6f5f5ebeeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#修改train.sh保持所有的参数和文件名一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6951bee1-07d2-47ba-992d-3bb4c332f46a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "2025-03-22 13:10:20.760919: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-22 13:10:20.782693: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742649020.808248    3487 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742649020.816334    3487 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-22 13:10:20.842215: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Flash Attention is not installed. Please install with `pip install flash-attn`, if you want to use SWA.\n",
      "03/22/2025 13:10:23 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: bf16\n",
      "\n",
      "Init rng with seed 42. Process_index is 0\n",
      "Init LLM Processor\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:05<00:00,  1.05s/it]\n",
      "The config attributes {'sample_size': 256, 'norm_type': None} were passed to AutoencoderKLMagvit, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "{'num_attention_heads', 'ch_mult', 'mid_block_type', 'mid_block_num_attention_heads', 'tile_sample_min_size', 'use_gc_blocks', 'tile_overlap_factor', 'upcast_vae', 'ch'} was not found in config. Values will be initialized to default values.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[] []\n",
      "loaded 3D transformer's pretrained weights from models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP/transformer ...\n",
      "{'position_of_clip_embedding'} was not found in config. Values will be initialized to default values.\n",
      "### missing keys: 0; \n",
      "### unexpected keys: 0;\n",
      "[]\n",
      "### All Parameters: 11799.265856 M\n",
      "### attn1 Parameters: 1812.54144 M\n",
      "Trainable modules '['.']'.\n",
      "Set time_embedding.linear_1.weight to lr : 2e-05\n",
      "Set time_embedding.linear_1.bias to lr : 2e-05\n",
      "Set time_embedding.linear_2.weight to lr : 2e-05\n",
      "Set time_embedding.linear_2.bias to lr : 2e-05\n",
      "Set proj.weight to lr : 2e-05\n",
      "Set proj.bias to lr : 2e-05\n",
      "Set text_proj.0.weight to lr : 2e-05\n",
      "Set text_proj.1.weight to lr : 2e-05\n",
      "Set text_proj.1.bias to lr : 2e-05\n",
      "Set transformer_blocks.0.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.0.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.0.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.0.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.0.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.0.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.0.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.0.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.0.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.0.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.0.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.0.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.0.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.0.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.0.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.0.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.0.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.0.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.0.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.0.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.0.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.0.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.0.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.0.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.0.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.0.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.0.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.0.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.0.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.0.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.0.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.0.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.0.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.0.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.0.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.0.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.0.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.0.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.0.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.0.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.1.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.1.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.1.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.1.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.1.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.1.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.1.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.1.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.1.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.1.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.1.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.1.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.1.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.1.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.1.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.1.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.1.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.1.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.1.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.1.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.1.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.1.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.1.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.1.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.1.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.1.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.1.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.1.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.1.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.1.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.1.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.1.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.1.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.1.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.1.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.1.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.1.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.1.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.1.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.1.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.2.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.2.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.2.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.2.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.2.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.2.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.2.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.2.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.2.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.2.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.2.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.2.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.2.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.2.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.2.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.2.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.2.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.2.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.2.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.2.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.2.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.2.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.2.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.2.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.2.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.2.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.2.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.2.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.2.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.2.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.2.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.2.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.2.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.2.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.2.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.2.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.2.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.2.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.2.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.2.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.3.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.3.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.3.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.3.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.3.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.3.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.3.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.3.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.3.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.3.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.3.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.3.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.3.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.3.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.3.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.3.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.3.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.3.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.3.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.3.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.3.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.3.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.3.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.3.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.3.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.3.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.3.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.3.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.3.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.3.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.3.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.3.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.3.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.3.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.3.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.3.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.3.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.3.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.3.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.3.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.4.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.4.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.4.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.4.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.4.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.4.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.4.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.4.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.4.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.4.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.4.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.4.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.4.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.4.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.4.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.4.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.4.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.4.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.4.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.4.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.4.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.4.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.4.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.4.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.4.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.4.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.4.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.4.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.4.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.4.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.4.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.4.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.4.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.4.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.4.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.4.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.4.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.4.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.4.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.4.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.5.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.5.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.5.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.5.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.5.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.5.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.5.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.5.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.5.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.5.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.5.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.5.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.5.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.5.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.5.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.5.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.5.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.5.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.5.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.5.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.5.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.5.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.5.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.5.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.5.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.5.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.5.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.5.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.5.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.5.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.5.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.5.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.5.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.5.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.5.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.5.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.5.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.5.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.5.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.5.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.6.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.6.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.6.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.6.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.6.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.6.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.6.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.6.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.6.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.6.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.6.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.6.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.6.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.6.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.6.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.6.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.6.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.6.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.6.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.6.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.6.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.6.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.6.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.6.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.6.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.6.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.6.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.6.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.6.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.6.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.6.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.6.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.6.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.6.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.6.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.6.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.6.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.6.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.6.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.6.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.7.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.7.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.7.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.7.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.7.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.7.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.7.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.7.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.7.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.7.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.7.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.7.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.7.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.7.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.7.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.7.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.7.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.7.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.7.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.7.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.7.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.7.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.7.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.7.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.7.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.7.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.7.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.7.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.7.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.7.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.7.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.7.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.7.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.7.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.7.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.7.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.7.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.7.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.7.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.7.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.8.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.8.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.8.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.8.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.8.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.8.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.8.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.8.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.8.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.8.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.8.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.8.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.8.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.8.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.8.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.8.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.8.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.8.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.8.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.8.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.8.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.8.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.8.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.8.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.8.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.8.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.8.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.8.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.8.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.8.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.8.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.8.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.8.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.8.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.8.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.8.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.8.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.8.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.8.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.8.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.9.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.9.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.9.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.9.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.9.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.9.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.9.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.9.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.9.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.9.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.9.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.9.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.9.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.9.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.9.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.9.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.9.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.9.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.9.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.9.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.9.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.9.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.9.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.9.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.9.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.9.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.9.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.9.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.9.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.9.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.9.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.9.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.9.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.9.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.9.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.9.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.9.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.9.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.9.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.9.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.10.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.10.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.10.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.10.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.10.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.10.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.10.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.10.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.10.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.10.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.10.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.10.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.10.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.10.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.10.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.10.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.10.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.10.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.10.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.10.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.10.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.10.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.10.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.10.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.10.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.10.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.10.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.10.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.10.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.10.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.10.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.10.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.10.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.10.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.10.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.10.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.10.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.10.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.10.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.10.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.11.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.11.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.11.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.11.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.11.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.11.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.11.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.11.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.11.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.11.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.11.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.11.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.11.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.11.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.11.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.11.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.11.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.11.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.11.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.11.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.11.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.11.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.11.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.11.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.11.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.11.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.11.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.11.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.11.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.11.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.11.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.11.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.11.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.11.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.11.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.11.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.11.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.11.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.11.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.11.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.12.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.12.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.12.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.12.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.12.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.12.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.12.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.12.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.12.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.12.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.12.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.12.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.12.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.12.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.12.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.12.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.12.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.12.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.12.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.12.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.12.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.12.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.12.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.12.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.12.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.12.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.12.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.12.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.12.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.12.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.12.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.12.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.12.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.12.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.12.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.12.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.12.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.12.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.12.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.12.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.13.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.13.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.13.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.13.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.13.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.13.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.13.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.13.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.13.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.13.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.13.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.13.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.13.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.13.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.13.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.13.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.13.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.13.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.13.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.13.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.13.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.13.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.13.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.13.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.13.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.13.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.13.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.13.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.13.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.13.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.13.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.13.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.13.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.13.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.13.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.13.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.13.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.13.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.13.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.13.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.14.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.14.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.14.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.14.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.14.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.14.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.14.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.14.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.14.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.14.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.14.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.14.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.14.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.14.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.14.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.14.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.14.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.14.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.14.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.14.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.14.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.14.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.14.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.14.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.14.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.14.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.14.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.14.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.14.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.14.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.14.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.14.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.14.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.14.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.14.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.14.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.14.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.14.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.14.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.14.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.15.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.15.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.15.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.15.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.15.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.15.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.15.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.15.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.15.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.15.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.15.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.15.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.15.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.15.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.15.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.15.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.15.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.15.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.15.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.15.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.15.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.15.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.15.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.15.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.15.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.15.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.15.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.15.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.15.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.15.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.15.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.15.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.15.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.15.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.15.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.15.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.15.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.15.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.15.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.15.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.16.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.16.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.16.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.16.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.16.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.16.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.16.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.16.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.16.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.16.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.16.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.16.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.16.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.16.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.16.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.16.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.16.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.16.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.16.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.16.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.16.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.16.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.16.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.16.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.16.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.16.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.16.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.16.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.16.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.16.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.16.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.16.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.16.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.16.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.16.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.16.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.16.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.16.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.16.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.16.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.17.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.17.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.17.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.17.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.17.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.17.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.17.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.17.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.17.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.17.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.17.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.17.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.17.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.17.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.17.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.17.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.17.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.17.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.17.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.17.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.17.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.17.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.17.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.17.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.17.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.17.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.17.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.17.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.17.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.17.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.17.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.17.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.17.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.17.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.17.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.17.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.17.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.17.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.17.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.17.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.18.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.18.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.18.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.18.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.18.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.18.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.18.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.18.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.18.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.18.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.18.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.18.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.18.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.18.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.18.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.18.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.18.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.18.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.18.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.18.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.18.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.18.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.18.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.18.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.18.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.18.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.18.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.18.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.18.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.18.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.18.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.18.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.18.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.18.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.18.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.18.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.18.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.18.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.18.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.18.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.19.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.19.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.19.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.19.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.19.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.19.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.19.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.19.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.19.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.19.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.19.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.19.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.19.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.19.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.19.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.19.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.19.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.19.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.19.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.19.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.19.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.19.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.19.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.19.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.19.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.19.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.19.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.19.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.19.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.19.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.19.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.19.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.19.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.19.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.19.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.19.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.19.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.19.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.19.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.19.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.20.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.20.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.20.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.20.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.20.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.20.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.20.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.20.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.20.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.20.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.20.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.20.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.20.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.20.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.20.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.20.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.20.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.20.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.20.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.20.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.20.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.20.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.20.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.20.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.20.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.20.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.20.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.20.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.20.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.20.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.20.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.20.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.20.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.20.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.20.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.20.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.20.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.20.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.20.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.20.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.21.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.21.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.21.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.21.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.21.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.21.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.21.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.21.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.21.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.21.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.21.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.21.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.21.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.21.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.21.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.21.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.21.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.21.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.21.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.21.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.21.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.21.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.21.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.21.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.21.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.21.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.21.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.21.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.21.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.21.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.21.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.21.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.21.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.21.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.21.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.21.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.21.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.21.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.21.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.21.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.22.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.22.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.22.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.22.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.22.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.22.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.22.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.22.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.22.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.22.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.22.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.22.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.22.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.22.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.22.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.22.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.22.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.22.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.22.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.22.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.22.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.22.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.22.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.22.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.22.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.22.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.22.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.22.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.22.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.22.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.22.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.22.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.22.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.22.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.22.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.22.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.22.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.22.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.22.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.22.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.23.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.23.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.23.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.23.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.23.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.23.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.23.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.23.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.23.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.23.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.23.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.23.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.23.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.23.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.23.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.23.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.23.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.23.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.23.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.23.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.23.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.23.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.23.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.23.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.23.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.23.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.23.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.23.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.23.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.23.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.23.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.23.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.23.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.23.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.23.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.23.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.23.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.23.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.23.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.23.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.24.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.24.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.24.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.24.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.24.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.24.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.24.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.24.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.24.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.24.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.24.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.24.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.24.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.24.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.24.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.24.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.24.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.24.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.24.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.24.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.24.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.24.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.24.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.24.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.24.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.24.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.24.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.24.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.24.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.24.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.24.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.24.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.24.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.24.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.24.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.24.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.24.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.24.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.24.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.24.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.25.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.25.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.25.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.25.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.25.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.25.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.25.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.25.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.25.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.25.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.25.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.25.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.25.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.25.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.25.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.25.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.25.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.25.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.25.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.25.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.25.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.25.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.25.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.25.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.25.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.25.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.25.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.25.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.25.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.25.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.25.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.25.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.25.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.25.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.25.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.25.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.25.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.25.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.25.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.25.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.26.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.26.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.26.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.26.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.26.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.26.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.26.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.26.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.26.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.26.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.26.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.26.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.26.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.26.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.26.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.26.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.26.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.26.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.26.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.26.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.26.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.26.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.26.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.26.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.26.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.26.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.26.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.26.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.26.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.26.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.26.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.26.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.26.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.26.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.26.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.26.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.26.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.26.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.26.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.26.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.27.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.27.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.27.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.27.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.27.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.27.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.27.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.27.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.27.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.27.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.27.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.27.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.27.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.27.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.27.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.27.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.27.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.27.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.27.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.27.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.27.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.27.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.27.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.27.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.27.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.27.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.27.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.27.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.27.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.27.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.27.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.27.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.27.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.27.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.27.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.27.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.27.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.27.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.27.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.27.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.28.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.28.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.28.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.28.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.28.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.28.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.28.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.28.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.28.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.28.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.28.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.28.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.28.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.28.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.28.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.28.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.28.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.28.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.28.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.28.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.28.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.28.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.28.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.28.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.28.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.28.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.28.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.28.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.28.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.28.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.28.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.28.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.28.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.28.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.28.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.28.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.28.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.28.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.28.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.28.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.29.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.29.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.29.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.29.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.29.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.29.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.29.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.29.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.29.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.29.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.29.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.29.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.29.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.29.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.29.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.29.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.29.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.29.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.29.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.29.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.29.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.29.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.29.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.29.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.29.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.29.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.29.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.29.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.29.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.29.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.29.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.29.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.29.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.29.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.29.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.29.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.29.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.29.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.29.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.29.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.30.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.30.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.30.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.30.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.30.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.30.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.30.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.30.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.30.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.30.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.30.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.30.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.30.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.30.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.30.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.30.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.30.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.30.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.30.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.30.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.30.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.30.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.30.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.30.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.30.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.30.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.30.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.30.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.30.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.30.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.30.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.30.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.30.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.30.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.30.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.30.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.30.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.30.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.30.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.30.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.31.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.31.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.31.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.31.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.31.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.31.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.31.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.31.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.31.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.31.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.31.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.31.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.31.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.31.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.31.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.31.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.31.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.31.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.31.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.31.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.31.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.31.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.31.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.31.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.31.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.31.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.31.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.31.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.31.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.31.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.31.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.31.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.31.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.31.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.31.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.31.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.31.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.31.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.31.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.31.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.32.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.32.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.32.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.32.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.32.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.32.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.32.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.32.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.32.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.32.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.32.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.32.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.32.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.32.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.32.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.32.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.32.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.32.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.32.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.32.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.32.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.32.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.32.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.32.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.32.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.32.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.32.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.32.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.32.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.32.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.32.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.32.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.32.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.32.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.32.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.32.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.32.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.32.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.32.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.32.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.33.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.33.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.33.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.33.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.33.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.33.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.33.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.33.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.33.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.33.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.33.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.33.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.33.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.33.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.33.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.33.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.33.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.33.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.33.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.33.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.33.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.33.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.33.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.33.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.33.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.33.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.33.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.33.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.33.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.33.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.33.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.33.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.33.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.33.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.33.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.33.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.33.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.33.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.33.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.33.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.34.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.34.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.34.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.34.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.34.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.34.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.34.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.34.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.34.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.34.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.34.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.34.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.34.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.34.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.34.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.34.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.34.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.34.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.34.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.34.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.34.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.34.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.34.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.34.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.34.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.34.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.34.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.34.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.34.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.34.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.34.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.34.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.34.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.34.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.34.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.34.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.34.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.34.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.34.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.34.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.35.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.35.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.35.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.35.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.35.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.35.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.35.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.35.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.35.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.35.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.35.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.35.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.35.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.35.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.35.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.35.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.35.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.35.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.35.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.35.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.35.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.35.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.35.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.35.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.35.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.35.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.35.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.35.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.35.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.35.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.35.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.35.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.35.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.35.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.35.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.35.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.35.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.35.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.35.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.35.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.36.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.36.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.36.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.36.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.36.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.36.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.36.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.36.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.36.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.36.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.36.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.36.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.36.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.36.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.36.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.36.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.36.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.36.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.36.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.36.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.36.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.36.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.36.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.36.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.36.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.36.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.36.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.36.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.36.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.36.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.36.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.36.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.36.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.36.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.36.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.36.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.36.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.36.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.36.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.36.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.37.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.37.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.37.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.37.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.37.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.37.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.37.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.37.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.37.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.37.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.37.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.37.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.37.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.37.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.37.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.37.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.37.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.37.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.37.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.37.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.37.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.37.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.37.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.37.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.37.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.37.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.37.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.37.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.37.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.37.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.37.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.37.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.37.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.37.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.37.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.37.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.37.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.37.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.37.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.37.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.38.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.38.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.38.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.38.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.38.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.38.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.38.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.38.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.38.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.38.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.38.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.38.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.38.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.38.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.38.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.38.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.38.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.38.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.38.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.38.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.38.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.38.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.38.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.38.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.38.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.38.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.38.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.38.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.38.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.38.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.38.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.38.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.38.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.38.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.38.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.38.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.38.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.38.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.38.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.38.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.39.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.39.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.39.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.39.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.39.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.39.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.39.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.39.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.39.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.39.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.39.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.39.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.39.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.39.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.39.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.39.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.39.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.39.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.39.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.39.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.39.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.39.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.39.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.39.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.39.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.39.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.39.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.39.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.39.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.39.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.39.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.39.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.39.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.39.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.39.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.39.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.39.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.39.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.39.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.39.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.40.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.40.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.40.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.40.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.40.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.40.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.40.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.40.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.40.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.40.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.40.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.40.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.40.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.40.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.40.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.40.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.40.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.40.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.40.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.40.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.40.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.40.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.40.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.40.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.40.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.40.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.40.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.40.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.40.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.40.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.40.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.40.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.40.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.40.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.40.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.40.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.40.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.40.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.40.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.40.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.41.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.41.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.41.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.41.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.41.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.41.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.41.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.41.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.41.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.41.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.41.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.41.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.41.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.41.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.41.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.41.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.41.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.41.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.41.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.41.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.41.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.41.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.41.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.41.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.41.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.41.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.41.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.41.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.41.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.41.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.41.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.41.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.41.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.41.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.41.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.41.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.41.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.41.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.41.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.41.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.42.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.42.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.42.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.42.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.42.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.42.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.42.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.42.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.42.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.42.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.42.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.42.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.42.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.42.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.42.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.42.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.42.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.42.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.42.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.42.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.42.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.42.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.42.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.42.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.42.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.42.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.42.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.42.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.42.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.42.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.42.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.42.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.42.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.42.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.42.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.42.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.42.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.42.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.42.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.42.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.43.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.43.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.43.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.43.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.43.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.43.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.43.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.43.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.43.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.43.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.43.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.43.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.43.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.43.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.43.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.43.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.43.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.43.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.43.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.43.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.43.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.43.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.43.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.43.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.43.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.43.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.43.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.43.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.43.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.43.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.43.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.43.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.43.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.43.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.43.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.43.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.43.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.43.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.43.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.43.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.44.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.44.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.44.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.44.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.44.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.44.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.44.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.44.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.44.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.44.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.44.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.44.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.44.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.44.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.44.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.44.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.44.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.44.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.44.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.44.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.44.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.44.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.44.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.44.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.44.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.44.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.44.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.44.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.44.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.44.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.44.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.44.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.44.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.44.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.44.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.44.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.44.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.44.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.44.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.44.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.45.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.45.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.45.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.45.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.45.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.45.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.45.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.45.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.45.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.45.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.45.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.45.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.45.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.45.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.45.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.45.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.45.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.45.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.45.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.45.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.45.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.45.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.45.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.45.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.45.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.45.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.45.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.45.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.45.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.45.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.45.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.45.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.45.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.45.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.45.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.45.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.45.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.45.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.45.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.45.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.46.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.46.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.46.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.46.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.46.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.46.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.46.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.46.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.46.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.46.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.46.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.46.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.46.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.46.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.46.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.46.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.46.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.46.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.46.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.46.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.46.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.46.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.46.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.46.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.46.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.46.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.46.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.46.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.46.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.46.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.46.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.46.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.46.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.46.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.46.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.46.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.46.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.46.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.46.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.46.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.47.norm1.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.47.norm1.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.47.norm1.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.47.norm1.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.47.attn1.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.47.attn1.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.47.attn1.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.47.attn1.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.47.attn1.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.47.attn1.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.47.attn1.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.47.attn1.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.47.attn1.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.47.attn1.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.47.attn1.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.47.attn1.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.47.attn2.norm_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.47.attn2.norm_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.47.attn2.norm_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.47.attn2.norm_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.47.attn2.to_q.weight to lr : 2e-05\n",
      "Set transformer_blocks.47.attn2.to_q.bias to lr : 2e-05\n",
      "Set transformer_blocks.47.attn2.to_k.weight to lr : 2e-05\n",
      "Set transformer_blocks.47.attn2.to_k.bias to lr : 2e-05\n",
      "Set transformer_blocks.47.attn2.to_v.weight to lr : 2e-05\n",
      "Set transformer_blocks.47.attn2.to_v.bias to lr : 2e-05\n",
      "Set transformer_blocks.47.attn2.to_out.0.weight to lr : 2e-05\n",
      "Set transformer_blocks.47.attn2.to_out.0.bias to lr : 2e-05\n",
      "Set transformer_blocks.47.norm2.linear.weight to lr : 2e-05\n",
      "Set transformer_blocks.47.norm2.linear.bias to lr : 2e-05\n",
      "Set transformer_blocks.47.norm2.norm.weight to lr : 2e-05\n",
      "Set transformer_blocks.47.norm2.norm.bias to lr : 2e-05\n",
      "Set transformer_blocks.47.ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.47.ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.47.ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.47.ff.net.2.bias to lr : 2e-05\n",
      "Set transformer_blocks.47.txt_ff.net.0.proj.weight to lr : 2e-05\n",
      "Set transformer_blocks.47.txt_ff.net.0.proj.bias to lr : 2e-05\n",
      "Set transformer_blocks.47.txt_ff.net.2.weight to lr : 2e-05\n",
      "Set transformer_blocks.47.txt_ff.net.2.bias to lr : 2e-05\n",
      "Set norm_final.weight to lr : 2e-05\n",
      "Set norm_final.bias to lr : 2e-05\n",
      "Set norm_out.linear.weight to lr : 2e-05\n",
      "Set norm_out.linear.bias to lr : 2e-05\n",
      "Set norm_out.norm.weight to lr : 2e-05\n",
      "Set norm_out.norm.bias to lr : 2e-05\n",
      "Set proj_out.weight to lr : 2e-05\n",
      "Set proj_out.bias to lr : 2e-05\n",
      "loading annotations from datasets/internal_datasets/metadata.json ...\n",
      "data scale: 2\n",
      "03/22/2025 13:12:02 - INFO - __main__ - ***** Running training *****\n",
      "03/22/2025 13:12:02 - INFO - __main__ -   Num examples = 2\n",
      "03/22/2025 13:12:02 - INFO - __main__ -   Num Epochs = 100\n",
      "03/22/2025 13:12:02 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "03/22/2025 13:12:02 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "03/22/2025 13:12:02 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "03/22/2025 13:12:02 - INFO - __main__ -   Total optimization steps = 200\n",
      "xx top 10 [0, 1] 0                                      | 0/200 [00:00<?, ?it/s]\n",
      "embed_dim=64 crops_coords=((2, 0), (28, 45)) grid_size=(12, 21) in_cache=0 cache_size=0\n",
      "\tembed_dim=64 data_size=torch.Size([3276, 64])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/EasyAnimate/scripts/train.py\", line 2250, in <module>\n",
      "    main()\n",
      "  File \"/home/ubuntu/EasyAnimate/scripts/train.py\", line 2041, in main\n",
      "    noise_pred = transformer3d(\n",
      "  File \"/usr/lib/python3/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/lib/python3/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/accelerate/utils/operations.py\", line 819, in forward\n",
      "    return model_forward(*args, **kwargs)\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/accelerate/utils/operations.py\", line 807, in __call__\n",
      "    return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
      "  File \"/usr/lib/python3/dist-packages/torch/amp/autocast_mode.py\", line 44, in decorate_autocast\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ubuntu/EasyAnimate/easyanimate/models/transformer3d.py\", line 1529, in forward\n",
      "    hidden_states = self.proj(hidden_states)\n",
      "  File \"/usr/lib/python3/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/lib/python3/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/lib/python3/dist-packages/torch/nn/modules/conv.py\", line 554, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/usr/lib/python3/dist-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n",
      "    return F.conv2d(\n",
      "RuntimeError: Given groups=1, weight of size [3072, 33, 2, 2], expected input[26, 16, 24, 42] to have 33 channels, but got 16 channels instead\n",
      "Steps:   0%|                                            | 0/200 [00:11<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
      "    args.func(args)\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 1194, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 780, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'scripts/train.py', '--pretrained_model_name_or_path=models/Diffusion_Transformer/EasyAnimateV5.1-12b-zh-InP', '--train_data_dir=datasets/internal_datasets/', '--train_data_meta=datasets/internal_datasets/metadata.json', '--config_path', 'config/easyanimate_video_v5.1_magvit_qwen.yaml', '--image_sample_size=1024', '--video_sample_size=256', '--token_sample_size=512', '--video_sample_stride=3', '--video_sample_n_frames=49', '--train_batch_size=1', '--video_repeat=1', '--gradient_accumulation_steps=1', '--dataloader_num_workers=8', '--num_train_epochs=100', '--checkpointing_steps=100', '--learning_rate=2e-05', '--lr_scheduler=constant_with_warmup', '--lr_warmup_steps=100', '--seed=42', '--output_dir=output_dir', '--gradient_checkpointing', '--mixed_precision=bf16', '--adam_weight_decay=5e-2', '--adam_epsilon=1e-10', '--vae_mini_batch=1', '--max_grad_norm=0.05', '--random_hw_adapt', '--training_with_video_token_length', '--loss_type=flow', '--enable_bucket', '--uniform_sampling', '--train_mode=normal', '--trainable_modules', '.']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "# 您可修改 scripts/train.sh 中的相关参数（如增大训练epoch数 num_train_epochs）来达到更好的性能。\n",
    "# 删去trainmodel=inpaint\n",
    "#注意metadata.json是image还是video\n",
    "#这是训练DiT的，DiT是什么参考：https://docs.google.com/document/d/1Ah6N8lZg4uIOAf0b4f8AoIeCjYcF1fJFYqTi7upDnKE/edit?tab=t.0\n",
    "!cd /workspace/EasyAnimate && sh scripts/train.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80c422a9-d8f8-4640-b703-cd1f0a330384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (3.0.3)\n",
      "Collecting jinja2\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 KB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2) (2.0.1)\n",
      "Installing collected packages: jinja2\n",
      "Successfully installed jinja2-3.1.6\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade jinja2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549e3d06-bbaa-47d7-a81f-9ff28979b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6dc008a-acff-4725-9ad6-6d104f15c0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 22 13:52:13 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.124.06             Driver Version: 570.124.06     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H100 PCIe               On  |   00000000:07:00.0 Off |                    0 |\n",
      "| N/A   31C    P0             48W /  350W |       1MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a20a14c9-31b1-4c0e-b838-fcd11afc5881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement cuda (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for cuda\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "667c4791-f0cf-49da-a8de-672bb9fc1519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2025 NVIDIA Corporation\n",
      "Built on Wed_Jan_15_19:20:09_PST_2025\n",
      "Cuda compilation tools, release 12.8, V12.8.61\n",
      "Build cuda_12.8.r12.8/compiler.35404655_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fdabb5-fe17-42f1-bbfb-29aba7307a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 移动训练好的LoRA模型到 EasyAnimate/models/Personalized_Model 目录中\n",
    "!cd EasyAnimate && mkdir -p models/Personalized_Model/ && mv output_dir/checkpoint-100.safetensors models/Personalized_Model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe79eefa-0dd9-4364-9b16-324d928bfa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 启动WebUI 在 Select LoRA model (选择LoRA模型[非必需]) 处选择训练好的LoRA模型\n",
    "!cd EasyAnimate && python app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5d9046-d80f-4748-8876-42968b3b873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip /workspace/EasyAnimate/datasets/00033-3725054118.zip -d /workspace/EasyAnimate/datasets/internal_datasets/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fcd558-7a90-4435-b723-d257f81c50b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip /workspace/EasyAnimate/datasets/train-20250321T172108Z-001.zip -d /workspace/EasyAnimate/datasets/internal_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ccaba2-1253-4b7b-9bda-eccaf9b7abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets/panda_70m/videos/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926f9576-02e8-44a4-bfcf-f4d8d4e0decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /workspace/EasyAnimate/easyanimate/video_caption/\n",
    "!sh ./scripts/stage_1_video_splitting.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb6210d-347e-4e4c-be27-48f8bf87d6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /workspace/EasyAnimate/easyanimate/video_caption\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a26fefa-265e-4583-9795-27068971a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d61b12c-bfb0-4b4c-b4ab-367424b20581",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat ./scripts/stage_1_video_splitting.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "358f58b5-f33d-4dbd-ad4b-1f004397e110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/EasyAnimate/easyanimate/video_caption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-22 00:58:23,156 - VideoCaption - \u001b[0;32mINFO\u001b[0m - 4 files in total. Save the result to /workspace/EasyAnimate/easyanimate/video_caption/datasets/panda_70m/videos/meta_file_info.jsonl.\n",
      "2025-03-22 00:58:23,837 - VideoCaption - \u001b[0;32mINFO\u001b[0m - -1hTK0wGrTg.mp4 has been processed.\n",
      "2025-03-22 00:58:23,837 - VideoCaption - \u001b[0;32mINFO\u001b[0m - -BgGhZs4K4w.mp4 has been processed.\n",
      "2025-03-22 00:58:23,837 - VideoCaption - \u001b[0;32mINFO\u001b[0m - -1urvnqfnfk.mp4 has been processed.\n",
      "2025-03-22 00:58:23,837 - VideoCaption - \u001b[0;32mINFO\u001b[0m - -AM0oWK3RBA.mp4 has been processed.\n",
      "100%|██████████████████████████████████████████| 4/4 [00:00<00:00, 13325.83it/s]\n",
      "2025-03-22 00:58:24,672 - VideoCaption - \u001b[0;32mINFO\u001b[0m - Save the gathered single jsonl file to /workspace/EasyAnimate/easyanimate/video_caption/datasets/panda_70m/videos/meta_scene_info.jsonl.\n",
      "2025-03-22 00:58:25,155 - VideoCaption - \u001b[0;32mINFO\u001b[0m - Filter 0 videos with resolution smaller than 262144.0.\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:38<00:00, 24.55s/it]\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/EasyAnimate/easyanimate/video_caption/\n",
    "!sh ./scripts/stage_1_video_splitting.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b236d1a-30bd-490d-b2b4-a79af40a0018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
