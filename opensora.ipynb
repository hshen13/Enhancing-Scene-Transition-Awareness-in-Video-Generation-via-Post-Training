{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOZlDFWwa5trC6DK/1tHeAn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hshen13/workable-colab/blob/main/opensora.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conda 的安装：\n"
      ],
      "metadata": {
        "id": "s10AZWIv_jba"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BYxAcoXyLNz"
      },
      "outputs": [],
      "source": [
        "mkdir -p ~/miniconda3\n",
        "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\n",
        "bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\n",
        "rm ~/miniconda3/miniconda.sh\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source ~/miniconda3/bin/activate\n"
      ],
      "metadata": {
        "id": "htTOcf2A_buy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Opensora的安装"
      ],
      "metadata": {
        "id": "ejgE32f8AHu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a virtual env and activate (conda as an example)\n",
        "conda create -n opensora python=3.10\n",
        "conda activate opensora\n",
        "\n",
        "\n",
        "#如果找不到opensora的虚拟环境，再安装一次conda\n",
        "\n",
        "# download the repo\n",
        "git clone https://github.com/hpcaitech/Open-Sora\n",
        "cd Open-Sora\n",
        "\n",
        "# Ensure torch >= 2.4.0\n",
        "#pip install -v . # for development mode, `pip install -v -e .`\n",
        "pip install -v -e .\n",
        "pip install xformers==0.0.27.post2 --index-url https://download.pytorch.org/whl/cu121 # install xformers according to your cuda version\n",
        "pip install flash-attn --no-build-isolation\n"
      ],
      "metadata": {
        "id": "ydyoD0c6_h-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "模型下载："
      ],
      "metadata": {
        "id": "Mp-8VyRGAOCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install \"huggingface_hub[cli]\"\n",
        "huggingface-cli download hpcai-tech/Open-Sora-v2 --local-dir ./ckpts\n"
      ],
      "metadata": {
        "id": "ZW6tsh78_c_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "继续安装其他依赖："
      ],
      "metadata": {
        "id": "CcpLO3yhBhZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandarallel # for parallel processing\n"
      ],
      "metadata": {
        "id": "xb9JVxDZ_8mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install cmake\n",
        "git clone https://github.com/hpcaitech/TensorNVMe.git && cd TensorNVMe\n",
        "pip install -r requirements.txt\n",
        "DISABLE_AIO=1 pip install -v --no-cache-dir .\n",
        "DISABLE_URING=1 pip install -v --no-cache-dir .\n",
        "\n",
        "\n",
        "conda install -c conda-forge libstdcxx-ng\n",
        "conda update libstdcxx-ng\n",
        "\n",
        "sudo apt-get update\n",
        "sudo apt-get install libaio1\n",
        "\n",
        "\n",
        "\n",
        "tensornvme check\n"
      ],
      "metadata": {
        "id": "_0rL6B6d_eAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " cd ..\n"
      ],
      "metadata": {
        "id": "U5_F0LZd_y8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "推理："
      ],
      "metadata": {
        "id": "BB9CusiGAQ5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torchrun --master_addr localhost --master_port 29500 --nproc_per_node 1 --standalone scripts/diffusion/inference.py configs/diffusion/inference/t2i2v_256px.py --save-dir samples --prompt \"raining, sea\""
      ],
      "metadata": {
        "id": "ocUBGHUu_zQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torchrun --nproc_per_node 1 --standalone scripts/diffusion/inference.py configs/diffusion/inference/t2i2v_256px.py --save-dir samples --prompt \"raining, sea\""
      ],
      "metadata": {
        "id": "85SD8DJw_6Bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "注意ubuntu主机地址的名称\n",
        "https://blog.csdn.net/lin_xiao_yi/article/details/132490694\n",
        "\n",
        "easyanimate可以lora，可以生成。\n"
      ],
      "metadata": {
        "id": "DA-Q-S89_-ll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "修改cache dir\n",
        "\n",
        "t5 = dict(\n",
        "    type=\"text_embedder\",\n",
        "    from_pretrained=\"google/t5-v1_1-xxl\",\n",
        "    cache_dir=\"/mnt/ddn/sora/tmp_load/huggingface/hub/\",\n",
        "    max_length=512,\n",
        "    shardformer=True,\n",
        ")\n",
        "clip = dict(\n",
        "    type=\"text_embedder\",\n",
        "    from_pretrained=\"openai/clip-vit-large-patch14\",\n",
        "    cache_dir=\"/mnt/ddn/sora/tmp_load/huggingface/hub/\",\n",
        "    max_length=77,\n",
        ")\n"
      ],
      "metadata": {
        "id": "TQsuWsBIACTZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "训练："
      ],
      "metadata": {
        "id": "UIkFf1K3ATDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#训练diffusion的脚本\n",
        "torchrun --nproc_per_node 1 scripts/diffusion/train.py configs/diffusion/train/stage1.py --d\n",
        "ataset.data-path datasets/pexels_45k_necessary.csv\n"
      ],
      "metadata": {
        "id": "5psiYkh8AD5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#训练vae的脚本\n",
        "torchrun --nproc_per_node 1 scripts/vae/train.py configs/vae/train/video_dc_ae_disc.py --dataset.data-path datasets/pexels_45k_necessary.csv"
      ],
      "metadata": {
        "id": "7utW8uZGAFLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "可以用我们写的脚本 data_scencetransition_opensora.ipynb生成符合opensora格式要求的csv\n",
        "https://colab.research.google.com/drive/1cC874FG1u6IVGlIiax6At5B9mug7kAts?usp=sharing\n",
        "\n",
        "\n",
        "\n",
        "我们的脚本DataPrepare_VideoWithScenceTransition.ipynb可以下载panda70m数据，切割出带有一个转场的10秒片段，text打标（对一个视频片段画面场景的文字描述）。\n",
        "\n",
        "\n",
        "https://colab.research.google.com/drive/1i_PO4Xw1Ke0EG8Y-mmOXj3EYN6mc5Ztj\n",
        "这个脚本生成的json文件格式为：\n",
        "/content/json_of_internal_datasets.json。 该json文件的格式如下：\n",
        " { \"file_path\": \"train/-1hTK0wGrTg_0-5.mp4\",\n",
        " \"text\": \"previous scene: a green neon sign that reads ' glo '; then next scence: a green logo for a company\",\n",
        "\"type\": \"video\" },\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "torchrun --nproc_per_node 1 --standalone scripts/vae/inference.py configs/vae/inference/video_dc_ae.py --save-dir samples/dcae  --model.from_pretrained outputs/250324_104951-vae_train_video_dc_ae_disc\n"
      ],
      "metadata": {
        "id": "uzDWTtm4AXOf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "数据集使用rclone 同步\n",
        "# https://rclone.org/install/\n"
      ],
      "metadata": {
        "id": "--Dvi-6mAZ_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rclone copy workspace gdrive:backup\n",
        "rclone copy workspace gdrive:newfolder --progress\n",
        "\n",
        "rmdir /home/ubuntu/internvl2_model/\n",
        "\n",
        "df -h\n",
        "\n",
        "\n",
        "rclone copy --max-age 24h --progress --no-traverse /path/to/src remote:\n",
        "zip -r /home/ubuntu/workspace/Colab_Video_Processing/video_caption.zip /home/ubuntu/workspace/Colab_Video_Processing/video_caption\n",
        "\n",
        "\n",
        "RTC:workspace/Colab_Video_Processing/video_caption\n",
        "\n",
        "rclone copy /home/ubuntu/workspace/Colab_Video_Processing/video_caption.zip gdrive:newfolder/Colab_Video_Processing/video_caption.zip --progress\n",
        "\n",
        "\n",
        "rclone copy /home/ubuntu/workspace/Colab_Video_Processing/video_caption.zip gdrive:newfolder/Colab_Video_Processing/video_caption.zip --progress"
      ],
      "metadata": {
        "id": "cANGASZ9AY1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torchrun --nproc_per_node 1 scripts/vae/train.py configs/vae/train/video_dc_ae_disc.py  --dataset.data-path datasets/video_analysis_result.csv\n"
      ],
      "metadata": {
        "id": "iujPbQZTAehS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}